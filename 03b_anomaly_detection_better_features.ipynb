{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection for UNSW NB-15 cyberattack dataset\n",
    "Identifying cyberattacks can be considered both a classification problem and an anomaly detection problem. In this notebook, I treat it as an anomaly detection problem. Given that [the training and test csv's provided by the researchers](https://cloudstor.aarnet.edu.au/plus/index.php/s/2DhnLGDdEECo4ys?path=%2FUNSW-NB15%20-%20CSV%20Files%2Fa%20part%20of%20training%20and%20testing%20set) are balanced between the normal and anomaly classes, I'm going to down-sample to reduce the available number of anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom modules\n",
    "import data_prep as dp \n",
    "import model_abstraction as moda\n",
    "\n",
    "# Data Structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "# Preprocessing or data manipulation methods\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Modeling methods and selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, StratifiedKFold\n",
    "\n",
    "# Anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Model assessment\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with more developed features\n",
    "The model selection process is similar to that of the previous notebook, however in this attempt the dataset is different. I've added more contextual features as one-hot-encoded variables, I've removed some features that were not useful in differentiating between attack and normal data, and have incorporated standard scaling for the numeric features that remain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3265: DtypeWarning: Columns (1,3,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3265: DtypeWarning: Columns (3,39,47) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Load train and test data\n",
    "X_train, y_train = dp.load_agg_Xy(path='./data/', sample_size=0.4, strat_cat='label')\n",
    "\n",
    "# Reformat for anomaly detection labeling\n",
    "y_train = y_train.apply(dp.y_anomaly_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create holdout set to verify generalizability of results\n",
    "X_train, X_hold, y_train, y_hold  = train_test_split(X_train,y_train, test_size = 0.25,\n",
    "                                                     random_state = 42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of anomaly detection methods used below start by training on normal data and building a profile. From there, they can be used to predict on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create 'masks' to filter the dataframe by whether or not the observation belongs to normal or attack class.\n",
    "train_normal = y_train==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bring in column transformations to process contextual features and standardize numerical values\n",
    "#with open('ct_ohe_ssc_xyagg.pkl', 'rb') as f:\n",
    "#    col_trans = pkl.load(f)\n",
    "\n",
    "# Define the individual steps\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "ssc_step = ('std_sclr', StandardScaler())\n",
    "\n",
    "# Make the step part of a pipeline\n",
    "ohe_pipe = Pipeline([ohe_step])\n",
    "ssc_pipe = Pipeline([ssc_step])\n",
    "\n",
    "# Columns to transform: categorical columns for encoding, numeric feature columns for standardizing\n",
    "ohe_cols = ['proto', 'state', 'service']\n",
    "binary_cols = ['is_sm_ips_ports', 'is_ftp_login']\n",
    "non_ssc_cols = ohe_cols+binary_cols\n",
    "ssc_cols = [col for col in X_train.columns if col not in non_ssc_cols]\n",
    "\n",
    "# Transformer input: tuple w/ contents ('name', SomeTransformer(Parameters), columns)\n",
    "transformer = [\n",
    "    ('one_hot_encoding', ohe_pipe, ohe_cols),\n",
    "    ('standard_scaling', ssc_pipe, ssc_cols)\n",
    "]\n",
    "col_trans = ColumnTransformer(transformers=transformer, remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:214: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:224: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n",
       "        max_features=1.0, max_samples='auto', n_estimators=100,\n",
       "        n_jobs=None, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ilf = IsolationForest()\n",
    "ilf.fit(col_trans.fit_transform(X_train[train_normal]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_pred_nm = ilf.predict(col_trans.transform(X_train[train_normal]))\n",
    "y_pred_out = ilf.predict(col_trans.transform(X_train[~train_normal]))\n",
    "y_pred_train = ilf.predict(col_trans.transform(X_train))\n",
    "y_pred_test = ilf.predict(col_trans.transform(X_hold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0,      0],\n",
       "       [ 66555, 599074]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train[train_normal], y_pred_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94344,  2041],\n",
       "       [    0,     0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train[~train_normal], y_pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94344,   2041],\n",
       "       [ 66555, 599074]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9395126924236064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 31484,    644],\n",
       "       [ 22394, 199483]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(roc_auc_score(y_hold, y_pred_test))\n",
    "confusion_matrix(y_hold, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:451: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ocsvm = OneClassSVM(kernel='rbf')\n",
    "ocsvm.fit(col_trans.transform(X_train[train_normal]))\n",
    "y_ocsvm_nm = ocsvm.fit_predict(col_trans.transform(X_train[train_normal]))\n",
    "y_ocsvm_out = ocsvm.predict(col_trans.transform(X_train[~train_normal]))\n",
    "y_ocsvm_train = ocsvm.predict(col_trans.transform(X_train))\n",
    "y_ocsvm_hold = ocsvm.predict(col_trans.transform(X_hold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train[train_normal], y_ocsvm_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train[~train_normal], y_ocsvm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_ocsvm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_hold, y_ocsvm_hold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliptical Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eenv = EllipticEnvelope(contamination=0.2, random_state=0)\n",
    "eenv.fit(col_trans.transform(X_train[train_normal]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,eenv.predict(col_trans.transform(X_hold)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lof = LocalOutlierFactor()\n",
    "y_pred = lof.fit_predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_scores = lof.negative_outlier_factor_\n",
    "out_scores = (neg_scores.max()-neg_scores)/(neg_scores.max()-neg_scores.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.315050e+05\n",
       "mean    -7.703878e+12\n",
       "std      2.633116e+14\n",
       "min     -2.320057e+16\n",
       "25%     -1.078605e+00\n",
       "50%     -1.004495e+00\n",
       "75%     -1.000000e+00\n",
       "max     -8.769621e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(neg_scores).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5005816494689044\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "for lim in np.linspace(1e-5,1e1,10):\n",
    "    print(roc_auc_score(y_train, list(map(y_anomaly_format, out_scores > lim))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5393576376419513"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
